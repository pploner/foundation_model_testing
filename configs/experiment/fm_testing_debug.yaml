# @package _global_

# to execute this experiment run:
# python train.py experiment=fm_testing

defaults:
  - override /data: collide2v
  - override /callbacks: default
  - override /trainer: default
  - override /model: tinyTransformer

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["collide2v", "tinyTransformer", "short_debug"]

data:
  train_val_test_split_per_class: [10000, 2000, 2000]
  label: "QCD_ggHbb_upscaled"
  to_classify:
    QCD: "QCD_inclusive"
    ggHbb: "ggHbb"

model:
  scheduler:
    _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
    _partial_: true
    patience: 2
    factor: 0.5
    min_lr: 1e-06

trainer:
  max_epochs: 10
